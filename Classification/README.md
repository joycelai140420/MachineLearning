Logistic Regression（逻辑回归）简介

逻辑回归是一种广泛用于分类问题的统计模型，尤其是在二分类问题中非常流行。它通过使用逻辑函数（Logistic function），也称为Sigmoid函数，将线性回归的输出映射到0和1之间，从而预测分类的概率。

算法原理
逻辑回归的基本形式可以表示为： 𝑦^=𝜎(𝑤𝑇𝑥+𝑏) 其中：
•	𝑥 是特征向量
•	𝑤 是权重向量
•	𝑏 是偏差（bias）
•	𝜎(𝑧) 是Sigmoid函数，定义为 𝜎(𝑧)=1/1+𝑒−𝑧

Sigmoid函数的输出是一个介于0和1之间的概率值，表示样本属于正类的概率。

应用
二分类问题：如垃圾邮件检测、疾病诊断、客户流失预测等。
多分类问题：通过一对多（OvR）或多对多（OvO）策略，可以扩展逻辑回归到多类分类问题。
概率评估：逻辑回归不仅给出分类结果，还能提供决策的概率基础，这对于需要评估风险的应用非常有用。

优点
1.	模型简单：逻辑回归模型形式简单，易于理解和实现。
2.	计算效率高：相比于复杂的模型，逻辑回归的训练和预测速度较快。
3.	输出概率：能够输出预测的概率，这对于需要概率解释的应用很有帮助。

缺点
1.	表达能力有限：逻辑回归假设数据是线性可分的，对于复杂的模式或非线性关系可能表现不佳。
2.	高度依赖数据表示：对特征工程高度依赖，数据预处理和特征选择的质量直接影响模型性能。

相关内容详解请参考台大Hung-yi Lee老师的课程。
![image](https://github.com/joycelai140420/MachineLearning/assets/167413809/c91df5d0-936c-4cfc-bd3d-13bcf4d4b71b)

实现逻辑回归的代码请参考：Logistic Regression.py


