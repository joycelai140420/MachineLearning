#!/usr/bin/env python
# coding: utf-8

# In[1]:


import numpy as np
'''
x: å½“å‰å‚æ•°çš„å€¼ã€‚
dx: å‚æ•°çš„æ¢¯åº¦ã€‚
cache: ç§»åŠ¨å¹³å‡çš„å¹³æ–¹æ¢¯åº¦ï¼Œåˆå§‹åŒ–ä¸ºé›¶çŸ©é˜µã€‚
lr (Learning Rate): å­¦ä¹ ç‡ï¼Œæ§åˆ¶å‚æ•°æ›´æ–°çš„æ­¥é•¿ã€‚
decay_rate: æ§åˆ¶å†å²ä¿¡æ¯åœ¨ç§»åŠ¨å¹³å‡ä¸­çš„ä¿ç•™ç¨‹åº¦ã€‚
epsilon: ç”¨äºæ•°å€¼ç¨³å®šæ€§çš„å°å¸¸æ•°ï¼Œé˜²æ­¢é™¤ä»¥é›¶ã€‚
'''
def rmsprop_update(x, dx, cache=None, lr=0.01, decay_rate=0.99, epsilon=1e-8):
    """
    A RMSprop update rule implementation using numpy.
    
    Inputs:
    - x: Current value of the parameter.
    - dx: Current gradient of the parameter.
    - cache: Moving average of squared gradients.
    - lr: Learning rate.
    - decay_rate: Decay rate for the moving average of squared gradients.
    - epsilon: Small constant for numerical stability.

    Returns:
    - next_x: Updated parameter value.
    - config: Updated cache with the new moving average of squared gradients.
    """
    if cache is None:
        cache = np.zeros_like(x)
    
    # Update cache with squared gradient
    #æ›´æ–°ç¼“å­˜ ï¼Œç¼“å­˜ç»´æŠ¤äº†å†å²æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°è¡°å‡å¹³å‡ã€‚
    cache = decay_rate * cache + (1 - decay_rate) * (dx ** 2)
    
    # Update the parameter
    #å‚æ•°æ›´æ–°:ä½¿ç”¨ç¼“å­˜å€¼è°ƒæ•´å­¦ä¹ ç‡å¹¶æ›´æ–°å‚æ•°
    x -= lr * dx / (np.sqrt(cache) + epsilon)
    
    return x, cache


# In[2]:


# Example usage
if __name__ == "__main__":
    # Assume some initial parameters
    x = np.array([1.0, 2.0, 3.0])
    dx = np.array([0.5, -0.5, 1.0])
    
    # Perform one update
    cache = None  # Initially, there's no cache
    learning_rate = 0.1
    decay_rate = 0.9
    epsilon = 1e-8
    
    x_updated, cache_updated = rmsprop_update(x, dx, cache, learning_rate, decay_rate, epsilon)
    #å±•ç¤ºäº†ç»è¿‡ä¸€æ¬¡ RMSProp æ›´æ–°åçš„å‚æ•°å€¼ã€‚
    print("Updated parameters:", x_updated)
    #æ˜¾ç¤ºäº†æ›´æ–°åçš„ç¼“å­˜å€¼ï¼Œå®ƒæ˜¯å¹³æ–¹æ¢¯åº¦çš„è¡°å‡å¹³å‡ã€‚
    print("Updated cache:", cache_updated)


# In[ ]:


#in TensorFlow.Keras use RMSProp 
from tensorflow.keras.optimizers import RMSprop
#rho å‚æ•°å¯¹åº”äºä¸Šé¢çš„è¡°å‡ç‡ ğ›¾ï¼Œè€Œ epsilon æ˜¯ä¸ºäº†æ•°å€¼ç¨³å®šæ€§æ·»åŠ çš„å°å¸¸æ•°ã€‚
model.compile(optimizer=RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

