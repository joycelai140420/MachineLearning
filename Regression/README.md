Regression（回归分析）和Logistic Regression（逻辑回归）不是一样的，它们是用于不同类型的预测问题的统计方法。


回归分析 (Regression Analysis)
回归分析是一种统计技术，用于建立一个或多个自变量（解释变量）与一个连续依变量（目标变量）之间的关系模型。其目的是预测或解释一个数值型的响应变量。最常见的回归分析是线性回归（Linear Regression），其中模型预测的是一个线性方程。例如，预测房屋价格基于其面积、房间数等因素。

逻辑回归 (Logistic Regression)
逻辑回归，虽然名称中包含“回归”，但实际上是一种用于分类问题的统计方法，特别是二分类问题。它用于预测一个二元依变量（目标变量是两个类别中的一个，通常表示为0和1）的概率。逻辑回归模型输出一个在0到1之间的数值，这个数值通常被解释为属于某个类别的概率。例如，根据病人的各种体征数据来预测是否有心脏病。

主要差异
目标类型：
  线性回归：预测连续的数值型输出。
  逻辑回归：预测二元分类的概率（例如，是/否，0/1）。
输出：
  线性回归：输出一个任意范围内的数值。
  逻辑回归：输出一个在0和1之间的概率值，通过S型函数（Sigmoid function）转换线性方程的输出。
应用：
  线性回归：用于预测那些量度型的数据，如金额、重量、温度等。
  逻辑回归：用于预测事件发生的概率，如是否发生某种疾病、用户是否点击广告等。


![image](https://github.com/joycelai140420/MachineLearning/assets/167413809/b8c98fdf-3ddb-40d7-a306-31c5b9ff6752)

简易描述差异就是线性回归（Linear Regression）本质上是一系列变量的线性组合再加上偏置项b，而逻辑回归（Logistic Regression） 是在线性回归（Linear Regression） 的基础上加了一层sigmoid函数，将线性函数转变为非线性函数。sigmoid函数的形状呈现为“S”形（如下图所示），它能将任意实数映射到0-1之间的某个概率值上。

tips:
loss function : 如果我们function是Estimation error 估测误差，就是跟目标值的差异，差越多就是越不好的function，差越多小就是越好的function 。所以要选最小的ˋ差min，用 这个arg min L(w,b)，再用Gradient Descent去解这个function。
