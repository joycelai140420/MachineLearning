LLM 簡介
大模型指的是那些拥有大量参数和复杂结构的机器学习模型，比如深度神经网络。这些模型有能力从大数据中学习到非常复杂的模式和关系。一个经典的例子是语言模型GPT-3，它通过训练海量文本数据，能够生成几乎人类水平的文本回答。

大数据和大模型结合在一起，可以解决许多过去难以想象的问题。比如，自动驾驶汽车需要处理大量的传感器数据，并做出实时决策；个性化推荐系统需要从用户的历史行为中挖掘出他们的偏好。

接著一下就來自於臺大老師Hung-yi Lee課程內容。（當然也會穿插一些其他老師和我的解釋）

以下是來自於openAI的paper，其標題是Scaling Laws for Neural Language Models論文，裡面就展示大模型多資料結果有多好。縱軸是當我們訓練一個語言模型的時候（文字接龍），你可以想成縱軸是文字接龍的loss或是文字接龍的錯誤率。那麼你模型的參數量越來越多，文字接龍預測下一個字的結果錯誤率越低。數據量越大，結果錯誤率越低。
![1715650248836](https://github.com/joycelai140420/MachineLearning/assets/167413809/840a952b-e999-4914-bb2f-d7b2ed225e53)

在模型越來越大的時候，就會突然頓悟，根據下面這個論文顯示，他常識讓各種不同大小的模型去解八各不同任務。用了google的LaMDA ，openAI的GPT-3還有Gopher和Chinchilla（Gopher和Chinchilla是DeepMind）等等，虛線表示隨機亂猜的結果。發現當模型的參數從10M到1B時候，其實表現是一樣，跟隨機都差不多。在慢慢到100billion參數時候，正確率開始起飛，會突然頓悟，神秘的頓悟現象。
所以從小模型開發到中模型的時候，在分析過程，先不要只看正確率，可以看解題過程，也許過程是對的，就有點信心可以從小模型一直慢慢變成大模型。

![1715652556044](https://github.com/joycelai140420/MachineLearning/assets/167413809/6b4a02c0-f384-44b7-ae1b-73f0139198df)

之前有講到Chain of Thought時候發現，你要告訴模型你在想問題的時候，要step by steps，這樣正確率才高，但這種結果只成立在大模型裡。下面縱軸是解數學的正確率，橫軸是模型參數從小到大。可以看到在10B之前時候，有做還比沒做的差。參數量變大，會突然頓悟。

實驗有包含Chain of Thought跟Instruction tuning、scratchpad（跟Chain of Thought差不多意思）、Calibration（模型知不知道自己在瞎掰，在瞎掰的時候會不會心虛，也就是說文字在接龍的時候，會預測下一個字的機率，這個機率代表一個信心分數，機率高表示對自己的回答是有信心）表現都是一致認同上面觀點。

![1715652907714](https://github.com/joycelai140420/MachineLearning/assets/167413809/64ba875f-bea3-499f-8726-5e8459f644fa)

如果我們分析機器答題的正確率跟他信心之間的關係進行分析,下圖左上角的paper裡面有說明，橫軸代表機器在答題的時候，他答題的信心分數。縱軸是指那個答案真正對的時候機率有多大。顏色從黃到深藍色指的是不同大小模型。黃色是最大模型，藍色是最小的。

然後小模型他的信心分數跟他的正確答案機率關係並不大。只有大模型才有正相關。有就是說小模型不管是不是瞎掰，也不再乎。反觀，大模型是知道自己沒信心在瞎掰，對自己知道的會比較有底氣。這個指的是Calibration能力。

右邊這張圖，ECE指的是Calibration程度，ECE值越小越好，ECE對應到左邊這張圖的對角線，跟每個顏色模型之間所夾得面積，發現到小模型10B之前是不會有Calibration現象，到10B之後某個瞬間又起飛。

![1715653698468](https://github.com/joycelai140420/MachineLearning/assets/167413809/9a8bee53-277c-48c3-ab45-9664cdd0dd3b)


