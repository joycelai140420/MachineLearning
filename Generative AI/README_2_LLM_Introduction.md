LLM 簡介
大模型指的是那些拥有大量参数和复杂结构的机器学习模型，比如深度神经网络。这些模型有能力从大数据中学习到非常复杂的模式和关系。一个经典的例子是语言模型GPT-3，它通过训练海量文本数据，能够生成几乎人类水平的文本回答。

大数据和大模型结合在一起，可以解决许多过去难以想象的问题。比如，自动驾驶汽车需要处理大量的传感器数据，并做出实时决策；个性化推荐系统需要从用户的历史行为中挖掘出他们的偏好。

接著一下就來自於臺大老師Hung-yi Lee課程內容。（當然也會穿插一些其他老師和我的解釋）

以下是來自於openAI的paper，其標題是Scaling Laws for Neural Language Models論文，裡面就展示大模型多資料結果有多好。縱軸是當我們訓練一個語言模型的時候（文字接龍），你可以想成縱軸是文字接龍的loss或是文字接龍的錯誤率。那麼你模型的參數量越來越多，文字接龍預測下一個字的結果錯誤率越低。數據量越大，結果錯誤率越低。
![1715650248836](https://github.com/joycelai140420/MachineLearning/assets/167413809/840a952b-e999-4914-bb2f-d7b2ed225e53)

在模型越來越大的時候，就會突然頓悟，根據下面這個論文顯示，他常識讓各種不同大小的模型去解八各不同任務。用了google的LaMDA ，openAI的GPT-3還有Gopher和Chinchilla（Gopher和Chinchilla是DeepMind）等等，虛線表示隨機亂猜的結果。發現當模型的參數從10M到1B時候，其實表現是一樣，跟隨機都差不多。在慢慢到100billion參數時候，正確率開始起飛，會突然頓悟，神秘的頓悟現象。
所以從小模型開發到中模型的時候，在分析過程，先不要只看正確率，可以看解題過程，也許過程是對的，就有點信心可以從小模型一直慢慢變成大模型。

![1715652556044](https://github.com/joycelai140420/MachineLearning/assets/167413809/6b4a02c0-f384-44b7-ae1b-73f0139198df)

之前有講到Chain of Thought時候發現，你要告訴模型你在想問題的時候，要step by steps，這樣正確率才高，但這種結果只成立在大模型裡。下面縱軸是解數學的正確率，橫軸是模型參數從小到大。可以看到在10B之前時候，有做還比沒做的差。參數量變大，會突然頓悟。

實驗有包含Chain of Thought跟Instruction tuning、scratchpad（跟Chain of Thought差不多意思）、Calibration（模型知不知道自己在瞎掰，在瞎掰的時候會不會心虛，也就是說文字在接龍的時候，會預測下一個字的機率，這個機率代表一個信心分數，機率高表示對自己的回答是有信心）表現都是一致認同上面觀點。

![1715652907714](https://github.com/joycelai140420/MachineLearning/assets/167413809/64ba875f-bea3-499f-8726-5e8459f644fa)

如果我們分析機器答題的正確率跟他信心之間的關係進行分析,下圖左上角的paper裡面有說明，橫軸代表機器在答題的時候，他答題的信心分數。縱軸是指那個答案真正對的時候機率有多大。顏色從黃到深藍色指的是不同大小模型。黃色是最大模型，藍色是最小的。

然後小模型他的信心分數跟他的正確答案機率關係並不大。只有大模型才有正相關。有就是說小模型不管是不是瞎掰，也不再乎。反觀，大模型是知道自己沒信心在瞎掰，對自己知道的會比較有底氣。這個指的是Calibration能力。

右邊這張圖，ECE指的是Calibration程度，ECE值越小越好，ECE對應到左邊這張圖的對角線，跟每個顏色模型之間所夾得面積，發現到小模型10B之前是不會有Calibration現象，到10B之後某個瞬間又起飛。

![1715653698468](https://github.com/joycelai140420/MachineLearning/assets/167413809/9a8bee53-277c-48c3-ab45-9664cdd0dd3b)

那模型還能不能變大呢？從BERT、GPT-2、GPT-3、LaMDA還有沒有更大模型呢？舉例來說，有一個模型叫Switch Transformer 就有1.6T的參數，比GPT-3大三倍。它的結構就跟原本的 Transformer 有差異，他用了一個特殊的結構叫Mixture-expert，就是在這個大模型裡面其實有很多小模組。在用這個模型的時候，不是一次用全部的模組，只是每次調用一部分的模組出來使用，像下圖有一個任務只調用了模組2，另一邊只調用模組1，不一次用所有參數。這樣的好處是在使用上（inference）時候比較快。訓練的時候用到整個參數，但到inference的時候只使用部分的參數，可以節省資源。

![1715655946853](https://github.com/joycelai140420/MachineLearning/assets/167413809/ae513ed6-4566-4416-b45f-351e404ac4f0)


接下來將資料的重要性

下圖是一篇文章說明用多少資料來機器學到什麼樣的事情，LLM要能正確回答你的問題，需要兩個能力，第一個是對語言文法的認識（語言知識），還有對世界正常人都能理解知識（世界知識）。橫軸是訓練的資料量，發現只要1B的資料量，就可以讓機器學習到語言知識、語言的文法。然後看到資料量需要30B才能讓機器學習到這個世界的知識。

![1715734344451](https://github.com/joycelai140420/MachineLearning/assets/167413809/bd34075d-7fad-4465-9372-905e6e35cdba)

資料本身的前處理也是很重要，這裡引用的論文是使用Gopher（Deepmind）這個模型，來參考一下人家怎麼做資料前處理，他們在網路上爬到很多資料，以下是他們前處理流程，那方法具体怎么处理每个步骤的内容，是我而外添加

1.Content Filtering(Gopher是透过google 安全搜寻的功能去过滤)

    過濾有害的內容，去除明显低质量的内容，如广告、色青暴力、导航栏等。
    使用正则表达式或标记语言识别并去除常见的广告和网页模板内容。
    基于内容长度、词汇丰富度等指标筛选出低质量内容。

2.Text Extraction
    去除HTML tag，保留换行、项目符号等

    常见方式有
    1. HTML 解析:将网页的HTML内容解析成易于处理的结构。使用HTML解析库（如BeautifulSoup或lxml）将原始HTML文档解析成树状结构
    2.内容定位:识别并定位网页中的主要内容区块。使用XPath或CSS选择器定位网页中的主要内容区块（如文章正文、标题等）。
    3.文本抽取:从定位的内容区块中提取纯文本。提取区块内的纯文本内容，去除HTML标签。使用正则表达式或文本处理库清洗提取的文本，保留的空格和换行符，让机器知道是个段落。
    4.语言检测:检测并标记文本的语言，确保只保留目标语言的数据。使用语言检测算法（如langid.py或fastText）识别文本的语言。过滤掉非目标语言的文本，确保数据集的一致性。

3.Quality Filtering
    用规则去除「低品质」资料。例如网页有包含自动生成的内容，还有社交媒体内容可能缺乏上下文、连贯性或实质内容。用了简单的understood heuristic filters:删除任何不包含50到100000个单词或平均单词长度超过3到10个字符范围的文档。移除哈希符号或省略号的符号与单词之比大于0.1的任何文档。删除任何90%以上的行，以项目符号开头的，或30%以上以省略号的符号结尾的文档。还要求80%的单词至少包含一个字母字符，并应用停止词过滤来删除不包含以下两个英文单词的文档：the、be、to、of、and、that、have、with:这充分处里了表面上不包含连贯英文文本的英文文件。
    
    1.可读性检查：使用自动化工具评估文本的可读性。
    2.低信息量文本过滤：检测和删除含有少量信息或无实际内容的文本。
    3.广告和模板内容检测：使用正则表达式和模板匹配去除广告和常见网页模板内容。
    4.拼写和语法错误检测：检测并修正严重的拼写和语法错误。
    5.语言过滤：确保文本符合目标语言要求。

4.Repetition Removal 和 Document Deduplication 去除重负资料
5.Test-set Filtering (这些文件是不会出现在训练集中的资料)

![1715734844665](https://github.com/joycelai140420/MachineLearning/assets/167413809/dca448d9-e144-4dee-bcad-85eadf7640ad)

去除重负的资料是非常重要，下图的论文，发现到拿掉重负的资料会有怎么样的改善

第一个（上）是原始，第二个跟第三个是不同层度的去重负表现。测试方法就是输入句子，然后将输出的答案去对照之前训练集的资料看有没有重负，机器有没有硬背，与训练集出现的句子重叠到某种比例。可以看到做过去重后，重叠比例低。

![1715738101610](https://github.com/joycelai140420/MachineLearning/assets/167413809/17df6ac5-d48f-49d0-ba5f-43aa2aa8f8aa)


如果在固定的运算资源下（没有选择的余地），我们只能选则小模型大资料还是大模型小资料，还是在那个中间点取得平衡呢？以下有个论文做了个实验，每一条颜色的虚线代表固定的运算资源，上是最小，下面是最大。纵轴是在做文字接龙的时候，训练集的效果，越低越好。横轴是参数量的大小。红圈是每个固定资源的中间平衡点拿出来。要找出平衡点。
![1715738472726](https://github.com/joycelai140420/MachineLearning/assets/167413809/0e1a4221-fd91-4f64-b498-c2e7b58da198)

将平衡点画在下图，横轴是运算资源，纵轴是参数量，当运算资源越来越多时候,参数量越大，训练资料量也要越来越多。这张图告诉我们最佳比例。

绿线是Gopher的算力和资料量，发现跟实际不符。然后deepmind为了验证这个结论，直接找一个模型训练看看，看实验的结果（Chinchila），根据这一条结论为基础去实做一个模型看这模型跟Gopher来进行比较。

![1715738717877](https://github.com/joycelai140420/MachineLearning/assets/167413809/8e1fcb25-b1a5-4282-9d11-5de902347133)

在同样算力对决发现大部分的任务，Chinchila都完胜Gopher，不过Chinchila也是很大，不是一般人可以轻松训练的模型。

![1715740678945](https://github.com/joycelai140420/MachineLearning/assets/167413809/68a23da6-4b33-433e-adc7-a359131c705b)

所以根据这个理论，下表来发现其他的模型参数量，在对应到所需要的训练集发现，很多模型都是资料量太少，所以彰显了资料量多的重要性.而LLaMA就可以看出他重视了大资料量的重要性，也采取相应的策略量

![1715740946025](https://github.com/joycelai140420/MachineLearning/assets/167413809/7e9ead6c-81f8-4479-b611-2e3e15c3edd9)

还有其他的方法可以快速让模型少量算力跟少量的资料就可以让你的模型快速提升，就是Instruction-tuning。

下面的论文就是用少量算力跟少量的资料来微调大模型，像PaLM是540B，而Instruction-tuning在1800任务上，只用到pre-trining的0.2%。

左下图横轴是参数量，纵轴是某些任务的正确率，如果没有做finetuning是黑线，随着你finetuning任务越来越多，正确率就提升很多。

右下图横轴是finetuning任务数量，纵轴是任务的正确率，发现都有提升

![1715741345933](https://github.com/joycelai140420/MachineLearning/assets/167413809/137da2cb-35a2-4e1f-8caf-005a8e5cc9bd)

再来根据Pre-train之后在根据人类老师给的打标签资料，就是Ghat-GPT成功的关键。可以看到每一代的架构都很类似这样的架构。

![1715742385443](https://github.com/joycelai140420/MachineLearning/assets/167413809/f8fd11e1-75c6-4d70-8713-bbb3b2594242)

看一下这样结合的效果怎么样呢？横轴是 model大小，纵轴是跟SFT 75B 直接互相比较的胜率。
红圈圈可以看出绿色的线6B有做Supervised Learning跟蓝色没做finetuning的175b比好一些。
蓝色圈圈可以看出绿色的线175B只做Supervised Learning跟1.3B最小模型（做Supervised Learning跟Reinforcement learning）相比，发现小模型是可以完成大模型的任务

![1715742565803](https://github.com/joycelai140420/MachineLearning/assets/167413809/18835bba-6a4b-4fa1-a7d1-a64ccf0c9ed7)



