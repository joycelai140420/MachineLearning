Generative AI 简介

    Generative AI（生成性人工智能）是一类人工智能技术，主要用于生成新的内容，包括文本、图像、音乐、语音等。

原理

    Generative AI通常基于机器学习模型，特别是生成模型。这些模型学习数据集的分布特性，以便生成新的、与训练数据相似的实例。
    简单来说就是让电脑学会脑补。

常见的生成模型包括
  
    生成对抗网络（GANs）：通过两个网络（生成器和鉴别器）的对抗过程进行学习。生成器生成尽可能真实的数据，而鉴别器尝试区分真实数据和生成器产生的数据。

    变分自编码器（VAEs）：使用概率编码的方法生成新的数据点，其通过编码输入数据到一个潜在空间，然后从这个潜在空间解码来生成数据。

    自回归模型：如PixelRNN，通过之前的数据点预测接下来的数据点。

    Transformer模型：依赖于自注意力机制，适用于处理序列数据，如文本和音频。GPT（生成预训练Transformer）和BERT就是此类模型的例子。

优点

    创新性和多样性：Generative AI可以创造全新的、多样化的内容，推动艺术和设计的界限。

    效率和自动化：在内容生成、模拟和其他多个领域提高效率，减少人工工作量。

    个性化内容：可以生成针对个人偏好和需求定制的内容，如个性化营销、推荐系统等。

缺点

    可控性问题：生成的内容可能难以预测和控制，尤其是在复杂的生成任务中。

    伦理和安全问题：包括生成虚假信息（如深度伪造）、侵犯版权和隐私问题等。

    质量波动：尤其在早期阶段，生成内容的质量可能不稳定，需要大量调整和优化。

Generative AI 这里就先以ChatGPT 开始作为一个方向，以下是来自于台大Hung-yi Lee老师的内容

ChatGPT ，G就是Generative，P就是Pre-trained，T就是Transformer。可以看出核心的几个方向的技术，而Pre-trained又称预训练、也称自督导式学习（Self-supervised Learning ，又叫基石模型（Foundation Model）。预训练又称是自督导式学习，就是人类提供大量的资料让机器学习。机器会透过一些方法，让资料形成成对样子，这种学习方式就称自督导式学习。而ChatGPT是由GPT产生出来的，所以叫做基石模型。所以预训练跟基石模型讲的是同一件事。

我们知道ChatGPT其实就是文字接龙，预训练就是上网获取大量资料，透过这些资料获得知识的过程。再透过继续学习（文献上称微调 finetune）。

督导式学习就是避免学到不好的讯息，要人类老师指导什么是错的什么是对的，一种大方向对错的引导。就例如刚出生的小孩，我们必须先教育他不能摸插头，不能吃大便，手怎么拿筷子，所以通常会有某些偏向性产生，毕竟每一个家庭教出来的小孩，家教都会有些不一样。

![1715219446800](https://github.com/joycelai140420/MachineLearning/assets/167413809/7f5a0590-b92d-40e6-a4c2-054948bf3f95)

预训练可能带来的帮助是举一反三的能力。实验证明在多种语言上做预训练，只要教某一个语言的某一个任务，自动学会其他语言的同样任务。BERT只是一种其中一个大语言模型之一。以此做范例。

![1715569441217](https://github.com/joycelai140420/MachineLearning/assets/167413809/b9366330-d063-4963-ad35-c10f2d5cf3d8)

真正实验数据显示，这是用DRCD一个中文机器阅读理解数据集（质量挺好的繁体中文数据集），让机器做的是中文阅读理解测验。他是要回答中文的问题，读中文的文章，问中问的问题，给出中文的回答。如果没做预训练，只给他一些中文的QA做微调，问中文的问题，假设我们这边看F1就是准确率可以看到中文回答的答案是78.1。然后用中文做预训练，用中文的QA做微调，F1可以提升到89.1。再来如果用104种语言做预训练，分别用中文或英文做微调，你会发现准确率都比没做预训练的高。当然这里人类测试的结果准确率是93.3%。

![1715570348333](https://github.com/joycelai140420/MachineLearning/assets/167413809/8c6afe7a-138f-464e-be9c-89361059dffe)

现在人们对于大型语言模型有两个方向的期待，老师姑且这样分类，一个是期待一成为主专才，专才就是专注于某个领域发光发热，另一个就是成为通才，有就是上知天文地理，下知鸡毛蒜皮。这两种期待导致两种不同类型的使用与大型语言模型的方式。

那么在这里我们先从专才的这边讲起。

BERT这个模型就是一个做文字填空的模型。通常我们使用它的时候，都是在期待一的情境下使用它。在他成为各种专才的时候，我们进行改造，改造有一种是添加外挂，另一种就是对他的参数做一些微调，才能变成某个任务的专才。

微调Finetune，就是有人输入good morning ，你就要输出早安。然后你就要微调语言模型里面内部的参数，让他可以变成一个翻译的专才，而这边的Finetune就是做gradient descent，将语言模型原来的参数当做训练的初始化参数，当做训练的inirialization(像之前做dnn初始化的参数都是随机)。有人输入good morning ，它才可以输出早安。因为bert本身劣势就是讲不出一句话，所以要加外挂才能讲的一句完整的话。而外挂需要另外训练出来的。需要一些标注的资料，才能够将外挂训练出来。

还有一个外挂的技术就是Adapter，就是语言模型我们都不动他，而外插入其他模组，在大型语言模型里面插入额外的插件，这个插件就是新增加一个layer等等。我们只要动Adapter里面参数。

这个Adapter插件，你可以看左下脚连接，里面有各式各样的插件。这边就是列了几种插件常用的插法。

Bitfit：
        把所有bias当做额外插件，做finetune时候只finetune那些neuron的bias，weight都不去动他。

Houlsby:
        虚线是一个transformer encoder的layer。Houlsby就在feed-forward network前面。

AdapterBias：
        是一个与feed-forward network模组平行的，他会对bitfit forward 的output做一些修改，把Bitfit forward的output做一下平移。

Prefix:
        他是去改attention

Lora:
        跟Diffusion model做结合，也是去改attention。在NLP表现很好，在语音上就表现不好。


![1715582069343](https://github.com/joycelai140420/MachineLearning/assets/167413809/0e04eea7-c622-44f2-ad50-32e333b9530f)

总之这些插件都要自已去试试看，如果有Adapter，可以降低自己Finetune做的参数量，只要对Adapter微调就可以，当我们要期待一个机器可以做的事情不止一个是很多个任务，如果不用插件，有100任务，你就要调整100模型形成100全新的模型，100个全新的参数。今天的模型都很大，GPT-3就有176个billion参数，这样一个一个调整是不可能。所以用插件的好处就是语言模型都不动，只对每一个任务的Adapter的查件作微调就可以，到时候要存的参数只有大型语言模型本身（GPT-3），然后每一个任务你只存各个任务的Adapter，一百个任务就存100个Adapter跟一个大型语言模型参数。

![1715583249283](https://github.com/joycelai140420/MachineLearning/assets/167413809/0853d6fd-e1e1-418e-8740-3e317a492c6f)



















