Generative AI 简介

    Generative AI（生成性人工智能）是一类人工智能技术，主要用于生成新的内容，包括文本、图像、音乐、语音等。

原理

    Generative AI通常基于机器学习模型，特别是生成模型。这些模型学习数据集的分布特性，以便生成新的、与训练数据相似的实例。
    简单来说就是让电脑学会脑补。

常见的生成模型包括
  
    生成对抗网络（GANs）：通过两个网络（生成器和鉴别器）的对抗过程进行学习。生成器生成尽可能真实的数据，而鉴别器尝试区分真实数据和生成器产生的数据。

    变分自编码器（VAEs）：使用概率编码的方法生成新的数据点，其通过编码输入数据到一个潜在空间，然后从这个潜在空间解码来生成数据。

    自回归模型：如PixelRNN，通过之前的数据点预测接下来的数据点。

    Transformer模型：依赖于自注意力机制，适用于处理序列数据，如文本和音频。GPT（生成预训练Transformer）和BERT就是此类模型的例子。

优点

    创新性和多样性：Generative AI可以创造全新的、多样化的内容，推动艺术和设计的界限。

    效率和自动化：在内容生成、模拟和其他多个领域提高效率，减少人工工作量。

    个性化内容：可以生成针对个人偏好和需求定制的内容，如个性化营销、推荐系统等。

缺点

    可控性问题：生成的内容可能难以预测和控制，尤其是在复杂的生成任务中。

    伦理和安全问题：包括生成虚假信息（如深度伪造）、侵犯版权和隐私问题等。

    质量波动：尤其在早期阶段，生成内容的质量可能不稳定，需要大量调整和优化。

Generative AI 这里就先以ChatGPT 开始作为一个方向，以下是来自于台大Hung-yi Lee老师的内容

ChatGPT ，G就是Generative，P就是Pre-trained，T就是Transformer。可以看出核心的几个方向的技术，而Pre-trained又称预训练、也称自督导式学习（Self-supervised Learning ，又叫基石模型（Foundation Model）。预训练又称是自督导式学习，就是人类提供大量的资料让机器学习。机器会透过一些方法，让资料形成成对样子，这种学习方式就称自督导式学习。而ChatGPT是由GPT产生出来的，所以叫做基石模型。所以预训练跟基石模型讲的是同一件事。

我们知道ChatGPT其实就是文字接龙，预训练就是上网获取大量资料，透过这些资料获得知识的过程。再透过继续学习（文献上称微调 finetune）。

督导式学习就是避免学到不好的讯息，要人类老师指导什么是错的什么是对的，一种大方向对错的引导。就例如刚出生的小孩，我们必须先教育他不能摸插头，不能吃大便，手怎么拿筷子，所以通常会有某些偏向性产生，毕竟每一个家庭教出来的小孩，家教都会有些不一样。

![1715219446800](https://github.com/joycelai140420/MachineLearning/assets/167413809/7f5a0590-b92d-40e6-a4c2-054948bf3f95)
