邻域嵌入（Neighbor Embedding）简介

Neighbor Embedding是一种用于数据降维和可视化的无监督学习技术，它主要用于探索高维数据的内在结构。这类方法的目标是在保持数据中邻近点的局部结构的同时，将高维数据映射到低维空间。最著名的邻域嵌入方法之一是 t-SNE（t-distributed Stochastic Neighbor Embedding）。
向台大老师这个图式如果用PCA就会像直接压扁的，无法把完整的S中的颜色有序排列。就需要Neighbor Embedding技术。

工作原理

保持邻近性：邻域嵌入技术试图确保如果两个数据点在高维空间中彼此接近，它们在低维映射中也应该保持接近。
距离度量：这通常通过优化一个目标函数来实现，该函数度量高维空间和低维空间中的距离差异。

应用场景

数据可视化：在处理复杂的数据集（如遗传数据或图像数据）时，邻域嵌入可以用来降维到2D或3D，使得可以通过可视化来理解数据结构。
特征提取：在预处理阶段，可以使用邻域嵌入作为特征提取的工具，以提高机器学习模型的性能。
异常检测：通过观察低维空间中数据点的分布，可以识别出异常值或离群点。
聚类分析：低维表示可以增强聚类算法的性能，尤其是在原始数据维度非常高时。

优点

有效保留局部结构：相比其他降维技术如PCA，邻域嵌入更擅长于保留数据的局部结构。
适应复杂的流形结构：能够处理位于复杂流形上的数据，这是许多线性降维技术难以实现的。

缺点

计算成本高：尤其是对于大型数据集，算法可能非常耗时。
超参数调整：如 t-SNE 中的困惑度（perplexity）参数需要仔细选择，不同的值可能导致结果差异很大。
难以解释：尽管低维嵌入可用于可视化，但它们通常难以解释，因为转换不如PCA那样直观。

训练时的注意事项

选择合适的超参数：例如，在 t-SNE 中，困惑度（perplexity）和学习率的选择对结果有显著影响。
规模与计算资源：对于非常大的数据集，可能需要使用更高效的算法版本或更多的计算资源。
初始化：特别是在 t-SNE 中，不同的初始化可能会导致结果的显著差异，有时使用 PCA 进行初始化可以提供更稳定的结果。
评估标准：在无监督学习中，没有明确的“准确率”衡量标准，因此需要通过可视化或其他质量评估方法来判断嵌入的质量。

提高训练结果的方法

多次运行与平均：由于邻域嵌入技术，尤其是 t-SNE，可能对初始条件敏感，多次运行并取结果的平均有助于获得更可靠的嵌入。
结合其他技术：有时将邻域嵌入与其他降维技术（如 PCA）结合使用，可以先减少数据的维度再进行邻域嵌入，以提高效率和稳定性。

以下是台大老师Hung-yi Lee授课内容
